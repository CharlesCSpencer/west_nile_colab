{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code found from http://www.davidsbatista.net/blog/2018/02/23/model_optimization/\n",
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=-1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model_params = {\n",
    "    'LogisticRegression' : {\n",
    "        'penalty' : ['l1', 'l2'],\n",
    "        'C' : np.arange(.05, 1, .05) },\n",
    "    'KNN' : {\n",
    "        'n_neighbors' : np.arange(3, 22, 2) },\n",
    "    'NaiveBayes' : {\n",
    "        'alpha' : np.arange(.05, 2, .05)},\n",
    "    'DecisionTree': {\n",
    "        'max_depth' : [None, 6, 10, 14], \n",
    "        'min_samples_leaf' : [1, 2],\n",
    "        'min_samples_split': [2, 3] },\n",
    "    'BaggedDecisionTree' : {\n",
    "        'n_estimators' : [20, 60, 100] },\n",
    "    'RandomForest' : {\n",
    "        'n_estimators' : [20, 60, 100],\n",
    "        'max_depth' : [None, 2, 6, 10],\n",
    "        'min_samples_split' : [2, 3, 4] },\n",
    "    'ExtraTrees' : {\n",
    "        'n_estimators' : [20, 60, 100],\n",
    "        'max_depth' : [None, 6, 10, 14],\n",
    "        'min_samples_leaf' : [1, 2], \n",
    "        'min_samples_split' : [2, 3], },\n",
    "    'AdaBoost' : {\n",
    "        'n_estimators' : np.arange(100, 151, 25),\n",
    "        'learning_rate' : np.linspace(0.05, 1, 10) },\n",
    "    'GradientBoosting' : {\n",
    "        'n_estimators' : np.arange(5, 150, 15),\n",
    "        'learning_rate' : np.linspace(0.05, 1, 10),\n",
    "        'max_depth' : [1, 2, 3] },\n",
    "    'SVM' : {\n",
    "        'C' : np.arange(0.05, 1, .05),\n",
    "        'kernel' : ['rbf', 'linear'] },\n",
    "     'XGBoost' : {\n",
    "        'n_estimators'  : np.arange(100, 151, 25), \n",
    "        'learning_rate' : np.arange(0.1, 1, .3),\n",
    "        'max_depth' : [3],\n",
    "        'alpha' : np.arange(0, 1, .3),\n",
    "        'lambda' : np.arange(0, 1, .3),\n",
    "        'gamma' : np.arange(0, 1, .3),\n",
    "        'subsample' : [.5],\n",
    "        'n_jobs' : [4],}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "sm = SMOTE(sampling_strategy=1,random_state=666)\n",
    "\n",
    "train = pd.read_csv('./data/train_weather.csv')\n",
    "train_dummies = pd.get_dummies(train,drop_first=True,columns=['Species','Street'])\n",
    "y = train_dummies['WnvPresent']\n",
    "X = train_dummies[[col for col in train_dummies.columns if col != 'WnvPresent']]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X,y,test_size = 0.3, random_state = 666)\n",
    "sampledX,sampledy = sm.fit_sample(train_x,train_y)\n",
    "sampledX=scaler.fit_transform(sampledX)\n",
    "test_x=scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_models = {\n",
    "#     'LogisticRegression' : LogisticRegression(random_state = 42),\n",
    "#     'KNN': KNeighborsClassifier(), \n",
    "# #     'NaiveBayes' : MultinomialNB(), #does not work with negative vals\n",
    "#     'DecisionTree' : DecisionTreeClassifier(random_state = 42), \n",
    "#     'BaggedDecisionTree' : BaggingClassifier(random_state = 42),\n",
    "#     'RandomForest' : RandomForestClassifier(random_state = 42), \n",
    "#     'ExtraTrees' : ExtraTreesClassifier(random_state = 42), \n",
    "#     'AdaBoost' : AdaBoostClassifier(random_state=42), \n",
    "    'GradientBoosting' : GradientBoostingClassifier(random_state = 42),\n",
    "#     'SVM' : SVC(random_state=42),\n",
    "    'XGBoost' : XGBClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoost.\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.8min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for SVM.\n",
      "Fitting 3 folds for each of 38 candidates, totalling 114 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 114 out of 114 | elapsed: 11.8min finished\n"
     ]
    }
   ],
   "source": [
    "search = EstimatorSelectionHelper(classifier_models, classifier_model_params)\n",
    "search.fit(sampledX,sampledy, scoring='recall', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then score our different models and output our results to a csv for archival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score2=search.score_summary(sort_by='max_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "score1=pd.concat([score1,score2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1.to_csv(r'.\\data\\score1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>estimator</th>\n",
       "      <th>kernel</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_score</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>penalty</th>\n",
       "      <th>std_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.991387</td>\n",
       "      <td>0.984927</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972868</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00853394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BaggedDecisionTree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991387</td>\n",
       "      <td>0.957221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.894057</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0447135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.991387</td>\n",
       "      <td>0.984927</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.972868</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00853394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.986219</td>\n",
       "      <td>0.971433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.945306</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>NaN</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>0.985788</td>\n",
       "      <td>0.959231</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.921189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0275946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>KNN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.955642</td>\n",
       "      <td>0.942578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.920758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0155291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.15</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.855154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.00379266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860034</td>\n",
       "      <td>0.855154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.00372689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964255</td>\n",
       "      <td>0.931668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.867356</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0454771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.9</td>\n",
       "      <td>SVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.94186</td>\n",
       "      <td>0.923629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.890612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0233892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C           estimator kernel learning_rate max_depth max_score  \\\n",
       "110   NaN          ExtraTrees    NaN           NaN      None  0.991387   \n",
       "66    NaN  BaggedDecisionTree    NaN           NaN       NaN  0.991387   \n",
       "113   NaN          ExtraTrees    NaN           NaN      None  0.991387   \n",
       "99    NaN        RandomForest    NaN           NaN        10  0.986219   \n",
       "60    NaN        DecisionTree    NaN           NaN        14  0.985788   \n",
       "38    NaN                 KNN    NaN           NaN       NaN  0.955642   \n",
       "5    0.15  LogisticRegression    NaN           NaN       NaN  0.860465   \n",
       "1    0.05  LogisticRegression    NaN           NaN       NaN  0.860034   \n",
       "23    NaN            AdaBoost    NaN      0.788889       NaN  0.964255   \n",
       "64    0.9                 SVM    rbf           NaN       NaN   0.94186   \n",
       "\n",
       "    mean_score min_samples_leaf min_samples_split min_score n_estimators  \\\n",
       "110   0.984927                2                 2  0.972868           60   \n",
       "66    0.957221              NaN               NaN  0.894057          100   \n",
       "113   0.984927                2                 3  0.972868           60   \n",
       "99    0.971433              NaN                 3  0.945306          100   \n",
       "60    0.959231                1                 2  0.921189          NaN   \n",
       "38    0.942578              NaN               NaN  0.920758          NaN   \n",
       "5     0.855154              NaN               NaN  0.851852          NaN   \n",
       "1     0.855154              NaN               NaN  0.850991          NaN   \n",
       "23    0.931668              NaN               NaN  0.867356          150   \n",
       "64    0.923629              NaN               NaN  0.890612          NaN   \n",
       "\n",
       "    n_neighbors penalty   std_score  \n",
       "110         NaN     NaN  0.00853394  \n",
       "66          NaN     NaN   0.0447135  \n",
       "113         NaN     NaN  0.00853394  \n",
       "99          NaN     NaN    0.018528  \n",
       "60          NaN     NaN   0.0275946  \n",
       "38            3     NaN   0.0155291  \n",
       "5           NaN      l2  0.00379266  \n",
       "1           NaN      l2  0.00372689  \n",
       "23          NaN     NaN   0.0454771  \n",
       "64          NaN     NaN   0.0233892  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1[score1['mean_score'] == score1.groupby('estimator')['mean_score'].transform('max')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
